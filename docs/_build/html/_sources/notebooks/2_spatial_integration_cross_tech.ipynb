{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FuseMap Tutorial II: Integrating Spatial Transcriptomics Data Across Different Technology Platforms\n",
    "\n",
    "In this tutorial, we'll demonstrate how to use FuseMap to integrate spatial transcriptomics data from different technology platforms - specifically, combining image-based (STARmap) and sequencing-based (Slide-seq) technologies. This integration is particularly challenging and important because:\n",
    "\n",
    "1. Different technologies capture spatial information at different resolutions\n",
    "2. The data formats and characteristics vary significantly between platforms\n",
    "3. The gene capture efficiency and coverage differ between methods\n",
    "\n",
    "We'll walk through each step carefully, explaining the rationale and technical details along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "For this tutorial, we'll use mouse brain data from two different platforms:\n",
    "\n",
    "- STARmap data: A high-resolution image-based spatial transcriptomics method (Shi et al., [Nature paper](https://www.nature.com/articles/s41586-023-06569-5#data-availability))\n",
    "- Slide-seq data: A sequencing-based spatial transcriptomics method with high throughput (Langlieb et al., [Nature paper](https://www.nature.com/articles/s41586-023-06818-7#data-availability))\n",
    "\n",
    "Both datasets are from mouse brain tissue, which allows us to demonstrate cross-platform integration while maintaining biological relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from easydict import EasyDict as edict\n",
    "from fusemap import seed_all, spatial_integrate, setup_logging, ModelType\n",
    "import logging\n",
    "import pandas as pd\n",
    "seed_all(0)\n",
    "\n",
    "# Set plotting style\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing\n",
    "\n",
    "When working with different technology platforms, careful preprocessing is crucial. Each platform has its own data characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to data\n",
    "data_dir_list = [\n",
    "    '/Users/mingzeyuan/Workspace/FuseMap/data/starmap.h5ad',\n",
    "    '/Users/mingzeyuan/Workspace/FuseMap/data/slideseq_Puck34.h5ad'\n",
    "]\n",
    "output_dir = '/Users/mingzeyuan/Workspace/FuseMap/output'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = edict(dict(output_save_dir=output_dir, \n",
    "                  keep_celltype=\"\", \n",
    "                  keep_tissueregion=\"\", \n",
    "                  use_llm_gene_embedding=\"false\", \n",
    "                  pretrain_model_path=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging(args.output_save_dir)\n",
    "\n",
    "arg_dict = vars(args)\n",
    "dict_pd = {}\n",
    "for keys in arg_dict.keys():\n",
    "    dict_pd[keys] = [arg_dict[keys]]\n",
    "pd.DataFrame(dict_pd).to_csv(args.output_save_dir  + \"config.csv\", index=False)\n",
    "logging.info(\"\\n\\n\\033[95mArguments:\\033[0m \\n%s\\n\\n\", vars(args))\n",
    "logging.info(\"\\n\\n\\033[95mArguments:\\033[0m \\n%s\\n\\n\", vars(ModelType))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Processing the Data\n",
    "For cross-platform integration, we need to handle the spatial coordinates carefully. Note that:\n",
    "- STARmap provides cell-level coordinates\n",
    "- Slide-seq provides bead/spot coordinates\n",
    "We will standardize these coordinates while preserving their relative positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = []\n",
    "for ind, data_dir in enumerate(data_dir_list):\n",
    "    print(f\"Loading {data_dir}\")\n",
    "    data = sc.read_h5ad(data_dir)\n",
    "    \n",
    "    # Handle spatial coordinates with platform-specific considerations\n",
    "    if \"x\" not in data.obs.columns:\n",
    "        if \"col\" in data.obs.columns and \"row\" in data.obs.columns:\n",
    "            data.obs[\"x\"] = data.obs[\"col\"]\n",
    "            data.obs[\"y\"] = data.obs[\"row\"]\n",
    "        elif \"spatial\" in data.obsm.keys():\n",
    "            data.obs[\"x\"] = data.obsm[\"spatial\"][:,0]\n",
    "            data.obs[\"y\"] = data.obsm[\"spatial\"][:,1]\n",
    "        elif 'Raw_Slideseq_X' in data.obs.columns and 'Raw_Slideseq_Y' in data.obs.columns:\n",
    "            data.obs[\"x\"] = data.obs['Raw_Slideseq_X']\n",
    "            data.obs[\"y\"] = data.obs['Raw_Slideseq_Y']\n",
    "        else:\n",
    "            raise ValueError(f\"Spatial coordinates not found in expected format for {data_dir}\")\n",
    "    \n",
    "    # Add dataset-specific metadata\n",
    "    data.obs['name'] = f'section{ind}'\n",
    "    data.obs['file_name'] = os.path.basename(data_dir)\n",
    "    data.obs['platform'] = 'STARmap' if 'starmap' in data_dir.lower() else 'Slide-seq'\n",
    "    \n",
    "    print(f\"Loaded {data.shape[0]} spots/cells with {data.shape[1]} genes from {data.obs['platform']}\")\n",
    "    X_input.append(data)\n",
    "\n",
    "# Set integration parameters\n",
    "# Use Delaunay triangulation for STARmap (cell-level) and KNN for Slide-seq (spot-level)\n",
    "kneighbor = [\"delaunay\", \"knn\"]\n",
    "input_identity = [\"ST\", \"ST\"]\n",
    "print(f\"Loaded {len(X_input)} datasets from different platforms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-platform Integration\n",
    "\n",
    "Now we'll perform the integration using FuseMap. The algorithm will:\n",
    "1. Learn platform-invariant features\n",
    "2. Preserve spatial relationships specific to each technology\n",
    "3. Create a unified representation of the tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the integration\n",
    "spatial_integrate(X_input, args, kneighbor, input_identity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read single-cell embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_embed=sc.read_h5ad(os.path.join(output_dir, 'ad_celltype_embedding.h5ad'))\n",
    "sc.pp.neighbors(ad_embed, n_neighbors=50,use_rep='X')\n",
    "sc.tl.umap(ad_embed)\n",
    "ax = sc.pl.umap(ad_embed,color='batch',size=1, show=False)\n",
    "ax.set_title('Single-cell embedding, colored by sample ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read spatial embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_embed=sc.read_h5ad(os.path.join(output_dir, 'ad_celltype_embedding.h5ad'))\n",
    "sc.pp.neighbors(ad_embed, n_neighbors=50,use_rep='X')\n",
    "sc.tl.umap(ad_embed)\n",
    "ax = sc.pl.umap(ad_embed,color='batch',size=1, show=False)\n",
    "ax.set_title('Single-cell embedding, colored by sample ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read gene embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_embed=sc.read_h5ad(os.path.join(output_dir, 'ad_celltype_embedding.h5ad'))\n",
    "sc.pp.neighbors(ad_embed, n_neighbors=50,use_rep='X')\n",
    "sc.tl.umap(ad_embed)\n",
    "ax = sc.pl.umap(ad_embed,color='batch',size=1, show=False)\n",
    "ax.set_title('Single-cell embedding, colored by sample ID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "initial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
